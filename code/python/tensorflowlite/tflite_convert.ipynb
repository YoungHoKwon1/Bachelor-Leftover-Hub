{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.0\n",
      "Help on class TFLiteConverterV2 in module tensorflow.lite.python.lite:\n",
      "\n",
      "class TFLiteConverterV2(TFLiteFrozenGraphConverterV2)\n",
      " |  TFLiteConverterV2(funcs, trackable_obj=None)\n",
      " |  \n",
      " |  Converts a TensorFlow model into TensorFlow Lite model.\n",
      " |  \n",
      " |  Attributes:\n",
      " |    optimizations: Experimental flag, subject to change. Set of optimizations to\n",
      " |      apply. e.g {tf.lite.Optimize.DEFAULT}. (default None, must be None or a\n",
      " |      set of values of type `tf.lite.Optimize`)\n",
      " |    representative_dataset: A generator function used for integer quantization\n",
      " |      where each generated sample has the same order, type and shape as the\n",
      " |      inputs to the model. Usually, this is a small subset of a few hundred\n",
      " |      samples randomly chosen, in no particular order, from the training or\n",
      " |      evaluation dataset. This is an optional attribute, but required for full\n",
      " |      integer quantization, i.e, if `tf.int8` is the only supported type in\n",
      " |      `target_spec.supported_types`. Refer to `tf.lite.RepresentativeDataset`.\n",
      " |      (default None)\n",
      " |    target_spec: Experimental flag, subject to change. Specifications of target\n",
      " |      device, including supported ops set, supported types and a set of user's\n",
      " |      defined TensorFlow operators required in the TensorFlow Lite runtime.\n",
      " |      Refer to `tf.lite.TargetSpec`.\n",
      " |    inference_input_type: Data type of the input layer. Note that integer types\n",
      " |      (tf.int8 and tf.uint8) are currently only supported for post training\n",
      " |      integer quantization and quantization aware training. (default tf.float32,\n",
      " |      must be in {tf.float32, tf.int8, tf.uint8})\n",
      " |    inference_output_type: Data type of the output layer. Note that integer\n",
      " |      types (tf.int8 and tf.uint8) are currently only supported for post\n",
      " |      training integer quantization and quantization aware training. (default\n",
      " |      tf.float32, must be in {tf.float32, tf.int8, tf.uint8})\n",
      " |    allow_custom_ops: Boolean indicating whether to allow custom operations.\n",
      " |      When False, any unknown operation is an error. When True, custom ops are\n",
      " |      created for any op that is unknown. The developer needs to provide these\n",
      " |      to the TensorFlow Lite runtime with a custom resolver. (default False)\n",
      " |    exclude_conversion_metadata: Whether not to embed the conversion metadata\n",
      " |      into the converted model. (default False)\n",
      " |    experimental_new_converter: Experimental flag, subject to change. Enables\n",
      " |      MLIR-based conversion. (default True)\n",
      " |    experimental_new_quantizer: Experimental flag, subject to change. Enables\n",
      " |      MLIR-based quantization conversion instead of Flatbuffer-based conversion.\n",
      " |      (default True)\n",
      " |    experimental_enable_resource_variables: Experimental flag, subject to\n",
      " |      change. Enables\n",
      " |      [resource variables](https://tensorflow.org/guide/migrate/tf1_vs_tf2#resourcevariables_instead_of_referencevariables)\n",
      " |      to be converted by this converter. This is only allowed if the\n",
      " |      from_saved_model interface is used. (default True)\n",
      " |  \n",
      " |  Example usage:\n",
      " |  \n",
      " |  ```python\n",
      " |  # Converting a SavedModel to a TensorFlow Lite model.\n",
      " |    converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
      " |    tflite_model = converter.convert()\n",
      " |  \n",
      " |  # Converting a tf.Keras model to a TensorFlow Lite model.\n",
      " |  converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
      " |  tflite_model = converter.convert()\n",
      " |  \n",
      " |  # Converting ConcreteFunctions to a TensorFlow Lite model.\n",
      " |  converter = tf.lite.TFLiteConverter.from_concrete_functions([func], model)\n",
      " |  tflite_model = converter.convert()\n",
      " |  \n",
      " |  # Converting a Jax model to a TensorFlow Lite model.\n",
      " |  converter = tf.lite.TFLiteConverter.experimental_from_jax([func], [[\n",
      " |      ('input1', input1), ('input2', input2)]])\n",
      " |  tflite_model = converter.convert()\n",
      " |  ```\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      TFLiteConverterV2\n",
      " |      TFLiteFrozenGraphConverterV2\n",
      " |      TFLiteConverterBaseV2\n",
      " |      TFLiteConverterBase\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, funcs, trackable_obj=None)\n",
      " |      Constructor for TFLiteConverter.\n",
      " |      \n",
      " |      Args:\n",
      " |        funcs: List of TensorFlow ConcreteFunctions. The list should not contain\n",
      " |          duplicate elements.\n",
      " |        trackable_obj: tf.AutoTrackable object associated with `funcs`. A\n",
      " |          reference to this object needs to be maintained so that Variables do not\n",
      " |          get garbage collected since functions have a weak reference to\n",
      " |          Variables. This is only required when the tf.AutoTrackable object is not\n",
      " |          maintained by the user (e.g. `from_saved_model`).\n",
      " |  \n",
      " |  convert(self)\n",
      " |      Converts a TensorFlow GraphDef based on instance variables.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The converted data in serialized format.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError:\n",
      " |          No concrete functions is specified.\n",
      " |          Multiple concrete functions are specified.\n",
      " |          Input shape is not specified.\n",
      " |          Invalid quantization parameters.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  experimental_from_jax(serving_funcs, inputs) from builtins.type\n",
      " |      Creates a TFLiteConverter object from a Jax model with its inputs.\n",
      " |      \n",
      " |      Args:\n",
      " |        serving_funcs: A array of Jax functions with all the weights applied\n",
      " |          already.\n",
      " |        inputs: A array of Jax input placeholders tuples list, e.g.,\n",
      " |          jnp.zeros(INPUT_SHAPE). Each tuple list should correspond with the\n",
      " |          serving function.\n",
      " |      \n",
      " |      Returns:\n",
      " |        TFLiteConverter object.\n",
      " |  \n",
      " |  from_concrete_functions(funcs, trackable_obj=None) from builtins.type\n",
      " |      Creates a TFLiteConverter object from ConcreteFunctions.\n",
      " |      \n",
      " |      Args:\n",
      " |        funcs: List of TensorFlow ConcreteFunctions. The list should not contain\n",
      " |          duplicate elements. Currently converter can only convert a single\n",
      " |          ConcreteFunction. Converting multiple functions is under development.\n",
      " |        trackable_obj:   An `AutoTrackable` object (typically `tf.module`)\n",
      " |          associated with `funcs`. A reference to this object needs to be\n",
      " |          maintained so that Variables do not get garbage collected since\n",
      " |          functions have a weak reference to Variables.\n",
      " |      \n",
      " |      Returns:\n",
      " |        TFLiteConverter object.\n",
      " |      \n",
      " |      Raises:\n",
      " |        Invalid input type.\n",
      " |  \n",
      " |  from_keras_model(model) from builtins.type\n",
      " |      Creates a TFLiteConverter object from a Keras model.\n",
      " |      \n",
      " |      Args:\n",
      " |        model: tf.Keras.Model\n",
      " |      \n",
      " |      Returns:\n",
      " |        TFLiteConverter object.\n",
      " |  \n",
      " |  from_saved_model(saved_model_dir, signature_keys=None, tags=None) from builtins.type\n",
      " |      Creates a TFLiteConverter object from a SavedModel directory.\n",
      " |      \n",
      " |      Args:\n",
      " |        saved_model_dir: SavedModel directory to convert.\n",
      " |        signature_keys: List of keys identifying SignatureDef containing inputs\n",
      " |          and outputs. Elements should not be duplicated. By default the\n",
      " |          `signatures` attribute of the MetaGraphdef is used. (default\n",
      " |          saved_model.signatures)\n",
      " |        tags: Set of tags identifying the MetaGraphDef within the SavedModel to\n",
      " |          analyze. All tags in the tag set must be present. (default\n",
      " |          {tf.saved_model.SERVING} or {'serve'})\n",
      " |      \n",
      " |      Returns:\n",
      " |        TFLiteConverter object.\n",
      " |      \n",
      " |      Raises:\n",
      " |        Invalid signature keys.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from TFLiteConverterBase:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "print(help(tf.lite.TFLiteConverter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load the model\n",
    "model = tf.keras.models.load_model('./models/modelMobileNetV2.h5')\n",
    "model_dir = './models/forPBtype/saved_model.pb'\n",
    "\n",
    "# Convert the model.\n",
    "# converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model('./models/forPBtype')\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_types = [tf.float16]\n",
    "tflite_quant_model = converter.convert()\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# debug_options = tf.lite.experimental.QuantizationDebugOptions(denylisted_nodes=suspected_layers)\n",
    "# debugger = tf.lite.experimental.QuantizationDebugger(\n",
    "#     converter=converter,\n",
    "#     debug_dataset=representative_dataset(ds),\n",
    "#     debug_options=debug_options)\n",
    "\n",
    "# Save the model.\n",
    "with open('quanted_model_16.tflite', 'wb') as f:\n",
    "  f.write(tflite_quant_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('./models/q_model2.h5')\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "# converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "quantized_tflite_model = converter.convert()\n",
    "\n",
    "# Save the model.\n",
    "with open('q_model2.tflite', 'wb') as f:\n",
    "  f.write(quantized_tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/youngho-kwon/OneDrive/바탕 화면/SeoulTech/2023 4학년 1학기/캡스톤 디자인(1)/ingredient_classifier_project/Leftover_Hub/leftover_hub/models/forPBtype\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/youngho-kwon/OneDrive/바탕 화면/SeoulTech/2023 4학년 1학기/캡스톤 디자인(1)/ingredient_classifier_project/Leftover_Hub/leftover_hub/models/forPBtype\\assets\n"
     ]
    }
   ],
   "source": [
    "save_dir = ''\n",
    "loaded_model = tf.keras.models.load_model(save_dir+'/modelMobileNetV2.h5')\n",
    "loaded_model.save(save_dir+'/forPBtype')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label to text file\n",
    "classes_list = ['apple', 'banana', 'beetroot', 'bell pepper', 'cabbage', 'capsicum', 'carrot', 'cauliflower', \n",
    "                'chilli pepper', 'corn', 'cucumber', 'eggplant', 'garlic', 'ginger', 'grapes', 'jalepeno', \n",
    "                'kiwi', 'lemon', 'lettuce',  'mango', 'onion', 'orange',  'paprika', \n",
    "                'pear', 'peas', 'pineapple', 'pomegrante', 'potato', 'raddish', 'soy beans', \n",
    "                'spinach', 'sweetcorn', 'sweetpotato', 'tomato', 'turnip', 'watermelon']\n",
    "\n",
    "def write_data(filename, data):\n",
    "    with open(filename, 'w') as f:\n",
    "        for line in data:\n",
    "            f.write(line + '\\n')\n",
    "write_data('labels.txt', classes_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
