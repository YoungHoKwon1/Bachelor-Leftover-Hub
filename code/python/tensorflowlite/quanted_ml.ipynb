{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML for TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# $ pip uninstall -y tensorflow\n",
    "# $ pip install -q tf-nightly\n",
    "# $ pip install -q tensorflow-model-optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -q tensorflow-model-optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow_model_optimization as tfmot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes_list = ['apple', 'banana', 'beetroot', 'bell pepper', 'cabbage', 'capsicum', 'carrot', 'cauliflower', \n",
    "                'chilli pepper', 'corn', 'cucumber', 'eggplant', 'garlic', 'ginger', 'grapes', 'jalepeno', \n",
    "                'kiwi', 'lemon', 'lettuce',  'mango', 'onion', 'orange',  'paprika', \n",
    "                'pear', 'peas', 'pineapple', 'pomegrante', 'potato', 'raddish', 'soy beans', \n",
    "                'spinach', 'sweetcorn', 'sweetpotato', 'tomato', 'turnip', 'watermelon']\n",
    "len(classes_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "#image_size = 256\n",
    "target_size = (256,256)\n",
    "input_shape = (256, 256, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3115 images belonging to 36 classes.\n",
      "Found 351 images belonging to 36 classes.\n",
      "Found 359 images belonging to 36 classes.\n"
     ]
    }
   ],
   "source": [
    "#Fetching train data and validation data and processing the data\n",
    "train_datagen = ImageDataGenerator(rescale = 1.00 / 255.0)\n",
    "val_datagen = ImageDataGenerator(rescale = 1.00 / 255.0)\n",
    "test_datagen = ImageDataGenerator(rescale = 1.00 / 255.0)\n",
    "\n",
    "train_dir = ''\n",
    "test_dir = ''\n",
    "val_dir = ''\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size = target_size,\n",
    "    batch_size = batch_size\n",
    "\n",
    ")\n",
    "\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size = target_size,\n",
    "    batch_size = batch_size\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size = target_size,\n",
    "    batch_size = batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\pyct\\static_analysis\\liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " quantize_layer (QuantizeLayer)  (None, 256, 256, 3)  3          ['input_5[0][0]']                \n",
      "                                                                                                  \n",
      " quant_Conv1 (QuantizeWrapperV2  (None, 128, 128, 32  929        ['quantize_layer[0][0]']         \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " quant_bn_Conv1 (QuantizeWrappe  (None, 128, 128, 32  129        ['quant_Conv1[0][0]']            \n",
      " rV2)                           )                                                                 \n",
      "                                                                                                  \n",
      " quant_Conv1_relu (QuantizeWrap  (None, 128, 128, 32  3          ['quant_bn_Conv1[0][0]']         \n",
      " perV2)                         )                                                                 \n",
      "                                                                                                  \n",
      " quant_expanded_conv_depthwise   (None, 128, 128, 32  291        ['quant_Conv1_relu[0][0]']       \n",
      " (QuantizeWrapperV2)            )                                                                 \n",
      "                                                                                                  \n",
      " quant_expanded_conv_depthwise_  (None, 128, 128, 32  129        ['quant_expanded_conv_depthwise[0\n",
      " BN (QuantizeWrapperV2)         )                                ][0]']                           \n",
      "                                                                                                  \n",
      " quant_expanded_conv_depthwise_  (None, 128, 128, 32  3          ['quant_expanded_conv_depthwise_B\n",
      " relu (QuantizeWrapperV2)       )                                N[0][0]']                        \n",
      "                                                                                                  \n",
      " quant_expanded_conv_project (Q  (None, 128, 128, 16  545        ['quant_expanded_conv_depthwise_r\n",
      " uantizeWrapperV2)              )                                elu[0][0]']                      \n",
      "                                                                                                  \n",
      " quant_expanded_conv_project_BN  (None, 128, 128, 16  67         ['quant_expanded_conv_project[0][\n",
      "  (QuantizeWrapperV2)           )                                0]']                             \n",
      "                                                                                                  \n",
      " quant_block_1_expand (Quantize  (None, 128, 128, 96  1729       ['quant_expanded_conv_project_BN[\n",
      " WrapperV2)                     )                                0][0]']                          \n",
      "                                                                                                  \n",
      " quant_block_1_expand_BN (Quant  (None, 128, 128, 96  385        ['quant_block_1_expand[0][0]']   \n",
      " izeWrapperV2)                  )                                                                 \n",
      "                                                                                                  \n",
      " quant_block_1_expand_relu (Qua  (None, 128, 128, 96  3          ['quant_block_1_expand_BN[0][0]']\n",
      " ntizeWrapperV2)                )                                                                 \n",
      "                                                                                                  \n",
      " quant_block_1_pad (QuantizeWra  (None, 129, 129, 96  1          ['quant_block_1_expand_relu[0][0]\n",
      " pperV2)                        )                                ']                               \n",
      "                                                                                                  \n",
      " quant_block_1_depthwise (Quant  (None, 64, 64, 96)  867         ['quant_block_1_pad[0][0]']      \n",
      " izeWrapperV2)                                                                                    \n",
      "                                                                                                  \n",
      " quant_block_1_depthwise_BN (Qu  (None, 64, 64, 96)  385         ['quant_block_1_depthwise[0][0]']\n",
      " antizeWrapperV2)                                                                                 \n",
      "                                                                                                  \n",
      " quant_block_1_depthwise_relu (  (None, 64, 64, 96)  3           ['quant_block_1_depthwise_BN[0][0\n",
      " QuantizeWrapperV2)                                              ]']                              \n",
      "                                                                                                  \n",
      " quant_block_1_project (Quantiz  (None, 64, 64, 24)  2353        ['quant_block_1_depthwise_relu[0]\n",
      " eWrapperV2)                                                     [0]']                            \n",
      "                                                                                                  \n",
      " quant_block_1_project_BN (Quan  (None, 64, 64, 24)  99          ['quant_block_1_project[0][0]']  \n",
      " tizeWrapperV2)                                                                                   \n",
      "                                                                                                  \n",
      " quant_block_2_expand (Quantize  (None, 64, 64, 144)  3745       ['quant_block_1_project_BN[0][0]'\n",
      " WrapperV2)                                                      ]                                \n",
      "                                                                                                  \n",
      " quant_block_2_expand_BN (Quant  (None, 64, 64, 144)  577        ['quant_block_2_expand[0][0]']   \n",
      " izeWrapperV2)                                                                                    \n",
      "                                                                                                  \n",
      " quant_block_2_expand_relu (Qua  (None, 64, 64, 144)  3          ['quant_block_2_expand_BN[0][0]']\n",
      " ntizeWrapperV2)                                                                                  \n",
      "                                                                                                  \n",
      " quant_block_2_depthwise (Quant  (None, 64, 64, 144)  1299       ['quant_block_2_expand_relu[0][0]\n",
      " izeWrapperV2)                                                   ']                               \n",
      "                                                                                                  \n",
      " quant_block_2_depthwise_BN (Qu  (None, 64, 64, 144)  577        ['quant_block_2_depthwise[0][0]']\n",
      " antizeWrapperV2)                                                                                 \n",
      "                                                                                                  \n",
      " quant_block_2_depthwise_relu (  (None, 64, 64, 144)  3          ['quant_block_2_depthwise_BN[0][0\n",
      " QuantizeWrapperV2)                                              ]']                              \n",
      "                                                                                                  \n",
      " quant_block_2_project (Quantiz  (None, 64, 64, 24)  3505        ['quant_block_2_depthwise_relu[0]\n",
      " eWrapperV2)                                                     [0]']                            \n",
      "                                                                                                  \n",
      " quant_block_2_project_BN (Quan  (None, 64, 64, 24)  99          ['quant_block_2_project[0][0]']  \n",
      " tizeWrapperV2)                                                                                   \n",
      "                                                                                                  \n",
      " quant_block_2_add (QuantizeWra  (None, 64, 64, 24)  3           ['quant_block_1_project_BN[0][0]'\n",
      " pperV2)                                                         , 'quant_block_2_project_BN[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " quant_block_3_expand (Quantize  (None, 64, 64, 144)  3745       ['quant_block_2_add[0][0]']      \n",
      " WrapperV2)                                                                                       \n",
      "                                                                                                  \n",
      " quant_block_3_expand_BN (Quant  (None, 64, 64, 144)  577        ['quant_block_3_expand[0][0]']   \n",
      " izeWrapperV2)                                                                                    \n",
      "                                                                                                  \n",
      " quant_block_3_expand_relu (Qua  (None, 64, 64, 144)  3          ['quant_block_3_expand_BN[0][0]']\n",
      " ntizeWrapperV2)                                                                                  \n",
      "                                                                                                  \n",
      " quant_block_3_pad (QuantizeWra  (None, 65, 65, 144)  1          ['quant_block_3_expand_relu[0][0]\n",
      " pperV2)                                                         ']                               \n",
      "                                                                                                  \n",
      " quant_block_3_depthwise (Quant  (None, 32, 32, 144)  1299       ['quant_block_3_pad[0][0]']      \n",
      " izeWrapperV2)                                                                                    \n",
      "                                                                                                  \n",
      " quant_block_3_depthwise_BN (Qu  (None, 32, 32, 144)  577        ['quant_block_3_depthwise[0][0]']\n",
      " antizeWrapperV2)                                                                                 \n",
      "                                                                                                  \n",
      " quant_block_3_depthwise_relu (  (None, 32, 32, 144)  3          ['quant_block_3_depthwise_BN[0][0\n",
      " QuantizeWrapperV2)                                              ]']                              \n",
      "                                                                                                  \n",
      " quant_block_3_project (Quantiz  (None, 32, 32, 32)  4673        ['quant_block_3_depthwise_relu[0]\n",
      " eWrapperV2)                                                     [0]']                            \n",
      "                                                                                                  \n",
      " quant_block_3_project_BN (Quan  (None, 32, 32, 32)  131         ['quant_block_3_project[0][0]']  \n",
      " tizeWrapperV2)                                                                                   \n",
      "                                                                                                  \n",
      " quant_block_4_expand (Quantize  (None, 32, 32, 192)  6529       ['quant_block_3_project_BN[0][0]'\n",
      " WrapperV2)                                                      ]                                \n",
      "                                                                                                  \n",
      " quant_block_4_expand_BN (Quant  (None, 32, 32, 192)  769        ['quant_block_4_expand[0][0]']   \n",
      " izeWrapperV2)                                                                                    \n",
      "                                                                                                  \n",
      " quant_block_4_expand_relu (Qua  (None, 32, 32, 192)  3          ['quant_block_4_expand_BN[0][0]']\n",
      " ntizeWrapperV2)                                                                                  \n",
      "                                                                                                  \n",
      " quant_block_4_depthwise (Quant  (None, 32, 32, 192)  1731       ['quant_block_4_expand_relu[0][0]\n",
      " izeWrapperV2)                                                   ']                               \n",
      "                                                                                                  \n",
      " quant_block_4_depthwise_BN (Qu  (None, 32, 32, 192)  769        ['quant_block_4_depthwise[0][0]']\n",
      " antizeWrapperV2)                                                                                 \n",
      "                                                                                                  \n",
      " quant_block_4_depthwise_relu (  (None, 32, 32, 192)  3          ['quant_block_4_depthwise_BN[0][0\n",
      " QuantizeWrapperV2)                                              ]']                              \n",
      "                                                                                                  \n",
      " quant_block_4_project (Quantiz  (None, 32, 32, 32)  6209        ['quant_block_4_depthwise_relu[0]\n",
      " eWrapperV2)                                                     [0]']                            \n",
      "                                                                                                  \n",
      " quant_block_4_project_BN (Quan  (None, 32, 32, 32)  131         ['quant_block_4_project[0][0]']  \n",
      " tizeWrapperV2)                                                                                   \n",
      "                                                                                                  \n",
      " quant_block_4_add (QuantizeWra  (None, 32, 32, 32)  3           ['quant_block_3_project_BN[0][0]'\n",
      " pperV2)                                                         , 'quant_block_4_project_BN[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " quant_block_5_expand (Quantize  (None, 32, 32, 192)  6529       ['quant_block_4_add[0][0]']      \n",
      " WrapperV2)                                                                                       \n",
      "                                                                                                  \n",
      " quant_block_5_expand_BN (Quant  (None, 32, 32, 192)  769        ['quant_block_5_expand[0][0]']   \n",
      " izeWrapperV2)                                                                                    \n",
      "                                                                                                  \n",
      " quant_block_5_expand_relu (Qua  (None, 32, 32, 192)  3          ['quant_block_5_expand_BN[0][0]']\n",
      " ntizeWrapperV2)                                                                                  \n",
      "                                                                                                  \n",
      " quant_block_5_depthwise (Quant  (None, 32, 32, 192)  1731       ['quant_block_5_expand_relu[0][0]\n",
      " izeWrapperV2)                                                   ']                               \n",
      "                                                                                                  \n",
      " quant_block_5_depthwise_BN (Qu  (None, 32, 32, 192)  769        ['quant_block_5_depthwise[0][0]']\n",
      " antizeWrapperV2)                                                                                 \n",
      "                                                                                                  \n",
      " quant_block_5_depthwise_relu (  (None, 32, 32, 192)  3          ['quant_block_5_depthwise_BN[0][0\n",
      " QuantizeWrapperV2)                                              ]']                              \n",
      "                                                                                                  \n",
      " quant_block_5_project (Quantiz  (None, 32, 32, 32)  6209        ['quant_block_5_depthwise_relu[0]\n",
      " eWrapperV2)                                                     [0]']                            \n",
      "                                                                                                  \n",
      " quant_block_5_project_BN (Quan  (None, 32, 32, 32)  131         ['quant_block_5_project[0][0]']  \n",
      " tizeWrapperV2)                                                                                   \n",
      "                                                                                                  \n",
      " quant_block_5_add (QuantizeWra  (None, 32, 32, 32)  3           ['quant_block_4_add[0][0]',      \n",
      " pperV2)                                                          'quant_block_5_project_BN[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " quant_block_6_expand (Quantize  (None, 32, 32, 192)  6529       ['quant_block_5_add[0][0]']      \n",
      " WrapperV2)                                                                                       \n",
      "                                                                                                  \n",
      " quant_block_6_expand_BN (Quant  (None, 32, 32, 192)  769        ['quant_block_6_expand[0][0]']   \n",
      " izeWrapperV2)                                                                                    \n",
      "                                                                                                  \n",
      " quant_block_6_expand_relu (Qua  (None, 32, 32, 192)  3          ['quant_block_6_expand_BN[0][0]']\n",
      " ntizeWrapperV2)                                                                                  \n",
      "                                                                                                  \n",
      " quant_block_6_pad (QuantizeWra  (None, 33, 33, 192)  1          ['quant_block_6_expand_relu[0][0]\n",
      " pperV2)                                                         ']                               \n",
      "                                                                                                  \n",
      " quant_block_6_depthwise (Quant  (None, 16, 16, 192)  1731       ['quant_block_6_pad[0][0]']      \n",
      " izeWrapperV2)                                                                                    \n",
      "                                                                                                  \n",
      " quant_block_6_depthwise_BN (Qu  (None, 16, 16, 192)  769        ['quant_block_6_depthwise[0][0]']\n",
      " antizeWrapperV2)                                                                                 \n",
      "                                                                                                  \n",
      " quant_block_6_depthwise_relu (  (None, 16, 16, 192)  3          ['quant_block_6_depthwise_BN[0][0\n",
      " QuantizeWrapperV2)                                              ]']                              \n",
      "                                                                                                  \n",
      " quant_block_6_project (Quantiz  (None, 16, 16, 64)  12417       ['quant_block_6_depthwise_relu[0]\n",
      " eWrapperV2)                                                     [0]']                            \n",
      "                                                                                                  \n",
      " quant_block_6_project_BN (Quan  (None, 16, 16, 64)  259         ['quant_block_6_project[0][0]']  \n",
      " tizeWrapperV2)                                                                                   \n",
      "                                                                                                  \n",
      " quant_block_7_expand (Quantize  (None, 16, 16, 384)  25345      ['quant_block_6_project_BN[0][0]'\n",
      " WrapperV2)                                                      ]                                \n",
      "                                                                                                  \n",
      " quant_block_7_expand_BN (Quant  (None, 16, 16, 384)  1537       ['quant_block_7_expand[0][0]']   \n",
      " izeWrapperV2)                                                                                    \n",
      "                                                                                                  \n",
      " quant_block_7_expand_relu (Qua  (None, 16, 16, 384)  3          ['quant_block_7_expand_BN[0][0]']\n",
      " ntizeWrapperV2)                                                                                  \n",
      "                                                                                                  \n",
      " quant_block_7_depthwise (Quant  (None, 16, 16, 384)  3459       ['quant_block_7_expand_relu[0][0]\n",
      " izeWrapperV2)                                                   ']                               \n",
      "                                                                                                  \n",
      " quant_block_7_depthwise_BN (Qu  (None, 16, 16, 384)  1537       ['quant_block_7_depthwise[0][0]']\n",
      " antizeWrapperV2)                                                                                 \n",
      "                                                                                                  \n",
      " quant_block_7_depthwise_relu (  (None, 16, 16, 384)  3          ['quant_block_7_depthwise_BN[0][0\n",
      " QuantizeWrapperV2)                                              ]']                              \n",
      "                                                                                                  \n",
      " quant_block_7_project (Quantiz  (None, 16, 16, 64)  24705       ['quant_block_7_depthwise_relu[0]\n",
      " eWrapperV2)                                                     [0]']                            \n",
      "                                                                                                  \n",
      " quant_block_7_project_BN (Quan  (None, 16, 16, 64)  259         ['quant_block_7_project[0][0]']  \n",
      " tizeWrapperV2)                                                                                   \n",
      "                                                                                                  \n",
      " quant_block_7_add (QuantizeWra  (None, 16, 16, 64)  3           ['quant_block_6_project_BN[0][0]'\n",
      " pperV2)                                                         , 'quant_block_7_project_BN[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " quant_block_8_expand (Quantize  (None, 16, 16, 384)  25345      ['quant_block_7_add[0][0]']      \n",
      " WrapperV2)                                                                                       \n",
      "                                                                                                  \n",
      " quant_block_8_expand_BN (Quant  (None, 16, 16, 384)  1537       ['quant_block_8_expand[0][0]']   \n",
      " izeWrapperV2)                                                                                    \n",
      "                                                                                                  \n",
      " quant_block_8_expand_relu (Qua  (None, 16, 16, 384)  3          ['quant_block_8_expand_BN[0][0]']\n",
      " ntizeWrapperV2)                                                                                  \n",
      "                                                                                                  \n",
      " quant_block_8_depthwise (Quant  (None, 16, 16, 384)  3459       ['quant_block_8_expand_relu[0][0]\n",
      " izeWrapperV2)                                                   ']                               \n",
      "                                                                                                  \n",
      " quant_block_8_depthwise_BN (Qu  (None, 16, 16, 384)  1537       ['quant_block_8_depthwise[0][0]']\n",
      " antizeWrapperV2)                                                                                 \n",
      "                                                                                                  \n",
      " quant_block_8_depthwise_relu (  (None, 16, 16, 384)  3          ['quant_block_8_depthwise_BN[0][0\n",
      " QuantizeWrapperV2)                                              ]']                              \n",
      "                                                                                                  \n",
      " quant_block_8_project (Quantiz  (None, 16, 16, 64)  24705       ['quant_block_8_depthwise_relu[0]\n",
      " eWrapperV2)                                                     [0]']                            \n",
      "                                                                                                  \n",
      " quant_block_8_project_BN (Quan  (None, 16, 16, 64)  259         ['quant_block_8_project[0][0]']  \n",
      " tizeWrapperV2)                                                                                   \n",
      "                                                                                                  \n",
      " quant_block_8_add (QuantizeWra  (None, 16, 16, 64)  3           ['quant_block_7_add[0][0]',      \n",
      " pperV2)                                                          'quant_block_8_project_BN[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " quant_block_9_expand (Quantize  (None, 16, 16, 384)  25345      ['quant_block_8_add[0][0]']      \n",
      " WrapperV2)                                                                                       \n",
      "                                                                                                  \n",
      " quant_block_9_expand_BN (Quant  (None, 16, 16, 384)  1537       ['quant_block_9_expand[0][0]']   \n",
      " izeWrapperV2)                                                                                    \n",
      "                                                                                                  \n",
      " quant_block_9_expand_relu (Qua  (None, 16, 16, 384)  3          ['quant_block_9_expand_BN[0][0]']\n",
      " ntizeWrapperV2)                                                                                  \n",
      "                                                                                                  \n",
      " quant_block_9_depthwise (Quant  (None, 16, 16, 384)  3459       ['quant_block_9_expand_relu[0][0]\n",
      " izeWrapperV2)                                                   ']                               \n",
      "                                                                                                  \n",
      " quant_block_9_depthwise_BN (Qu  (None, 16, 16, 384)  1537       ['quant_block_9_depthwise[0][0]']\n",
      " antizeWrapperV2)                                                                                 \n",
      "                                                                                                  \n",
      " quant_block_9_depthwise_relu (  (None, 16, 16, 384)  3          ['quant_block_9_depthwise_BN[0][0\n",
      " QuantizeWrapperV2)                                              ]']                              \n",
      "                                                                                                  \n",
      " quant_block_9_project (Quantiz  (None, 16, 16, 64)  24705       ['quant_block_9_depthwise_relu[0]\n",
      " eWrapperV2)                                                     [0]']                            \n",
      "                                                                                                  \n",
      " quant_block_9_project_BN (Quan  (None, 16, 16, 64)  259         ['quant_block_9_project[0][0]']  \n",
      " tizeWrapperV2)                                                                                   \n",
      "                                                                                                  \n",
      " quant_block_9_add (QuantizeWra  (None, 16, 16, 64)  3           ['quant_block_8_add[0][0]',      \n",
      " pperV2)                                                          'quant_block_9_project_BN[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " quant_block_10_expand (Quantiz  (None, 16, 16, 384)  25345      ['quant_block_9_add[0][0]']      \n",
      " eWrapperV2)                                                                                      \n",
      "                                                                                                  \n",
      " quant_block_10_expand_BN (Quan  (None, 16, 16, 384)  1537       ['quant_block_10_expand[0][0]']  \n",
      " tizeWrapperV2)                                                                                   \n",
      "                                                                                                  \n",
      " quant_block_10_expand_relu (Qu  (None, 16, 16, 384)  3          ['quant_block_10_expand_BN[0][0]'\n",
      " antizeWrapperV2)                                                ]                                \n",
      "                                                                                                  \n",
      " quant_block_10_depthwise (Quan  (None, 16, 16, 384)  3459       ['quant_block_10_expand_relu[0][0\n",
      " tizeWrapperV2)                                                  ]']                              \n",
      "                                                                                                  \n",
      " quant_block_10_depthwise_BN (Q  (None, 16, 16, 384)  1537       ['quant_block_10_depthwise[0][0]'\n",
      " uantizeWrapperV2)                                               ]                                \n",
      "                                                                                                  \n",
      " quant_block_10_depthwise_relu   (None, 16, 16, 384)  3          ['quant_block_10_depthwise_BN[0][\n",
      " (QuantizeWrapperV2)                                             0]']                             \n",
      "                                                                                                  \n",
      " quant_block_10_project (Quanti  (None, 16, 16, 96)  37057       ['quant_block_10_depthwise_relu[0\n",
      " zeWrapperV2)                                                    ][0]']                           \n",
      "                                                                                                  \n",
      " quant_block_10_project_BN (Qua  (None, 16, 16, 96)  387         ['quant_block_10_project[0][0]'] \n",
      " ntizeWrapperV2)                                                                                  \n",
      "                                                                                                  \n",
      " quant_block_11_expand (Quantiz  (None, 16, 16, 576)  56449      ['quant_block_10_project_BN[0][0]\n",
      " eWrapperV2)                                                     ']                               \n",
      "                                                                                                  \n",
      " quant_block_11_expand_BN (Quan  (None, 16, 16, 576)  2305       ['quant_block_11_expand[0][0]']  \n",
      " tizeWrapperV2)                                                                                   \n",
      "                                                                                                  \n",
      " quant_block_11_expand_relu (Qu  (None, 16, 16, 576)  3          ['quant_block_11_expand_BN[0][0]'\n",
      " antizeWrapperV2)                                                ]                                \n",
      "                                                                                                  \n",
      " quant_block_11_depthwise (Quan  (None, 16, 16, 576)  5187       ['quant_block_11_expand_relu[0][0\n",
      " tizeWrapperV2)                                                  ]']                              \n",
      "                                                                                                  \n",
      " quant_block_11_depthwise_BN (Q  (None, 16, 16, 576)  2305       ['quant_block_11_depthwise[0][0]'\n",
      " uantizeWrapperV2)                                               ]                                \n",
      "                                                                                                  \n",
      " quant_block_11_depthwise_relu   (None, 16, 16, 576)  3          ['quant_block_11_depthwise_BN[0][\n",
      " (QuantizeWrapperV2)                                             0]']                             \n",
      "                                                                                                  \n",
      " quant_block_11_project (Quanti  (None, 16, 16, 96)  55489       ['quant_block_11_depthwise_relu[0\n",
      " zeWrapperV2)                                                    ][0]']                           \n",
      "                                                                                                  \n",
      " quant_block_11_project_BN (Qua  (None, 16, 16, 96)  387         ['quant_block_11_project[0][0]'] \n",
      " ntizeWrapperV2)                                                                                  \n",
      "                                                                                                  \n",
      " quant_block_11_add (QuantizeWr  (None, 16, 16, 96)  3           ['quant_block_10_project_BN[0][0]\n",
      " apperV2)                                                        ',                               \n",
      "                                                                  'quant_block_11_project_BN[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " quant_block_12_expand (Quantiz  (None, 16, 16, 576)  56449      ['quant_block_11_add[0][0]']     \n",
      " eWrapperV2)                                                                                      \n",
      "                                                                                                  \n",
      " quant_block_12_expand_BN (Quan  (None, 16, 16, 576)  2305       ['quant_block_12_expand[0][0]']  \n",
      " tizeWrapperV2)                                                                                   \n",
      "                                                                                                  \n",
      " quant_block_12_expand_relu (Qu  (None, 16, 16, 576)  3          ['quant_block_12_expand_BN[0][0]'\n",
      " antizeWrapperV2)                                                ]                                \n",
      "                                                                                                  \n",
      " quant_block_12_depthwise (Quan  (None, 16, 16, 576)  5187       ['quant_block_12_expand_relu[0][0\n",
      " tizeWrapperV2)                                                  ]']                              \n",
      "                                                                                                  \n",
      " quant_block_12_depthwise_BN (Q  (None, 16, 16, 576)  2305       ['quant_block_12_depthwise[0][0]'\n",
      " uantizeWrapperV2)                                               ]                                \n",
      "                                                                                                  \n",
      " quant_block_12_depthwise_relu   (None, 16, 16, 576)  3          ['quant_block_12_depthwise_BN[0][\n",
      " (QuantizeWrapperV2)                                             0]']                             \n",
      "                                                                                                  \n",
      " quant_block_12_project (Quanti  (None, 16, 16, 96)  55489       ['quant_block_12_depthwise_relu[0\n",
      " zeWrapperV2)                                                    ][0]']                           \n",
      "                                                                                                  \n",
      " quant_block_12_project_BN (Qua  (None, 16, 16, 96)  387         ['quant_block_12_project[0][0]'] \n",
      " ntizeWrapperV2)                                                                                  \n",
      "                                                                                                  \n",
      " quant_block_12_add (QuantizeWr  (None, 16, 16, 96)  3           ['quant_block_11_add[0][0]',     \n",
      " apperV2)                                                         'quant_block_12_project_BN[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " quant_block_13_expand (Quantiz  (None, 16, 16, 576)  56449      ['quant_block_12_add[0][0]']     \n",
      " eWrapperV2)                                                                                      \n",
      "                                                                                                  \n",
      " quant_block_13_expand_BN (Quan  (None, 16, 16, 576)  2305       ['quant_block_13_expand[0][0]']  \n",
      " tizeWrapperV2)                                                                                   \n",
      "                                                                                                  \n",
      " quant_block_13_expand_relu (Qu  (None, 16, 16, 576)  3          ['quant_block_13_expand_BN[0][0]'\n",
      " antizeWrapperV2)                                                ]                                \n",
      "                                                                                                  \n",
      " quant_block_13_pad (QuantizeWr  (None, 17, 17, 576)  1          ['quant_block_13_expand_relu[0][0\n",
      " apperV2)                                                        ]']                              \n",
      "                                                                                                  \n",
      " quant_block_13_depthwise (Quan  (None, 8, 8, 576)   5187        ['quant_block_13_pad[0][0]']     \n",
      " tizeWrapperV2)                                                                                   \n",
      "                                                                                                  \n",
      " quant_block_13_depthwise_BN (Q  (None, 8, 8, 576)   2305        ['quant_block_13_depthwise[0][0]'\n",
      " uantizeWrapperV2)                                               ]                                \n",
      "                                                                                                  \n",
      " quant_block_13_depthwise_relu   (None, 8, 8, 576)   3           ['quant_block_13_depthwise_BN[0][\n",
      " (QuantizeWrapperV2)                                             0]']                             \n",
      "                                                                                                  \n",
      " quant_block_13_project (Quanti  (None, 8, 8, 160)   92481       ['quant_block_13_depthwise_relu[0\n",
      " zeWrapperV2)                                                    ][0]']                           \n",
      "                                                                                                  \n",
      " quant_block_13_project_BN (Qua  (None, 8, 8, 160)   643         ['quant_block_13_project[0][0]'] \n",
      " ntizeWrapperV2)                                                                                  \n",
      "                                                                                                  \n",
      " quant_block_14_expand (Quantiz  (None, 8, 8, 960)   155521      ['quant_block_13_project_BN[0][0]\n",
      " eWrapperV2)                                                     ']                               \n",
      "                                                                                                  \n",
      " quant_block_14_expand_BN (Quan  (None, 8, 8, 960)   3841        ['quant_block_14_expand[0][0]']  \n",
      " tizeWrapperV2)                                                                                   \n",
      "                                                                                                  \n",
      " quant_block_14_expand_relu (Qu  (None, 8, 8, 960)   3           ['quant_block_14_expand_BN[0][0]'\n",
      " antizeWrapperV2)                                                ]                                \n",
      "                                                                                                  \n",
      " quant_block_14_depthwise (Quan  (None, 8, 8, 960)   8643        ['quant_block_14_expand_relu[0][0\n",
      " tizeWrapperV2)                                                  ]']                              \n",
      "                                                                                                  \n",
      " quant_block_14_depthwise_BN (Q  (None, 8, 8, 960)   3841        ['quant_block_14_depthwise[0][0]'\n",
      " uantizeWrapperV2)                                               ]                                \n",
      "                                                                                                  \n",
      " quant_block_14_depthwise_relu   (None, 8, 8, 960)   3           ['quant_block_14_depthwise_BN[0][\n",
      " (QuantizeWrapperV2)                                             0]']                             \n",
      "                                                                                                  \n",
      " quant_block_14_project (Quanti  (None, 8, 8, 160)   153921      ['quant_block_14_depthwise_relu[0\n",
      " zeWrapperV2)                                                    ][0]']                           \n",
      "                                                                                                  \n",
      " quant_block_14_project_BN (Qua  (None, 8, 8, 160)   643         ['quant_block_14_project[0][0]'] \n",
      " ntizeWrapperV2)                                                                                  \n",
      "                                                                                                  \n",
      " quant_block_14_add (QuantizeWr  (None, 8, 8, 160)   3           ['quant_block_13_project_BN[0][0]\n",
      " apperV2)                                                        ',                               \n",
      "                                                                  'quant_block_14_project_BN[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " quant_block_15_expand (Quantiz  (None, 8, 8, 960)   155521      ['quant_block_14_add[0][0]']     \n",
      " eWrapperV2)                                                                                      \n",
      "                                                                                                  \n",
      " quant_block_15_expand_BN (Quan  (None, 8, 8, 960)   3841        ['quant_block_15_expand[0][0]']  \n",
      " tizeWrapperV2)                                                                                   \n",
      "                                                                                                  \n",
      " quant_block_15_expand_relu (Qu  (None, 8, 8, 960)   3           ['quant_block_15_expand_BN[0][0]'\n",
      " antizeWrapperV2)                                                ]                                \n",
      "                                                                                                  \n",
      " quant_block_15_depthwise (Quan  (None, 8, 8, 960)   8643        ['quant_block_15_expand_relu[0][0\n",
      " tizeWrapperV2)                                                  ]']                              \n",
      "                                                                                                  \n",
      " quant_block_15_depthwise_BN (Q  (None, 8, 8, 960)   3841        ['quant_block_15_depthwise[0][0]'\n",
      " uantizeWrapperV2)                                               ]                                \n",
      "                                                                                                  \n",
      " quant_block_15_depthwise_relu   (None, 8, 8, 960)   3           ['quant_block_15_depthwise_BN[0][\n",
      " (QuantizeWrapperV2)                                             0]']                             \n",
      "                                                                                                  \n",
      " quant_block_15_project (Quanti  (None, 8, 8, 160)   153921      ['quant_block_15_depthwise_relu[0\n",
      " zeWrapperV2)                                                    ][0]']                           \n",
      "                                                                                                  \n",
      " quant_block_15_project_BN (Qua  (None, 8, 8, 160)   643         ['quant_block_15_project[0][0]'] \n",
      " ntizeWrapperV2)                                                                                  \n",
      "                                                                                                  \n",
      " quant_block_15_add (QuantizeWr  (None, 8, 8, 160)   3           ['quant_block_14_add[0][0]',     \n",
      " apperV2)                                                         'quant_block_15_project_BN[0][0]\n",
      "                                                                 ']                               \n",
      "                                                                                                  \n",
      " quant_block_16_expand (Quantiz  (None, 8, 8, 960)   155521      ['quant_block_15_add[0][0]']     \n",
      " eWrapperV2)                                                                                      \n",
      "                                                                                                  \n",
      " quant_block_16_expand_BN (Quan  (None, 8, 8, 960)   3841        ['quant_block_16_expand[0][0]']  \n",
      " tizeWrapperV2)                                                                                   \n",
      "                                                                                                  \n",
      " quant_block_16_expand_relu (Qu  (None, 8, 8, 960)   3           ['quant_block_16_expand_BN[0][0]'\n",
      " antizeWrapperV2)                                                ]                                \n",
      "                                                                                                  \n",
      " quant_block_16_depthwise (Quan  (None, 8, 8, 960)   8643        ['quant_block_16_expand_relu[0][0\n",
      " tizeWrapperV2)                                                  ]']                              \n",
      "                                                                                                  \n",
      " quant_block_16_depthwise_BN (Q  (None, 8, 8, 960)   3841        ['quant_block_16_depthwise[0][0]'\n",
      " uantizeWrapperV2)                                               ]                                \n",
      "                                                                                                  \n",
      " quant_block_16_depthwise_relu   (None, 8, 8, 960)   3           ['quant_block_16_depthwise_BN[0][\n",
      " (QuantizeWrapperV2)                                             0]']                             \n",
      "                                                                                                  \n",
      " quant_block_16_project (Quanti  (None, 8, 8, 320)   307841      ['quant_block_16_depthwise_relu[0\n",
      " zeWrapperV2)                                                    ][0]']                           \n",
      "                                                                                                  \n",
      " quant_block_16_project_BN (Qua  (None, 8, 8, 320)   1283        ['quant_block_16_project[0][0]'] \n",
      " ntizeWrapperV2)                                                                                  \n",
      "                                                                                                  \n",
      " quant_Conv_1 (QuantizeWrapperV  (None, 8, 8, 1280)  412161      ['quant_block_16_project_BN[0][0]\n",
      " 2)                                                              ']                               \n",
      "                                                                                                  \n",
      " quant_Conv_1_bn (QuantizeWrapp  (None, 8, 8, 1280)  5121        ['quant_Conv_1[0][0]']           \n",
      " erV2)                                                                                            \n",
      "                                                                                                  \n",
      " quant_out_relu (QuantizeWrappe  (None, 8, 8, 1280)  3           ['quant_Conv_1_bn[0][0]']        \n",
      " rV2)                                                                                             \n",
      "                                                                                                  \n",
      " quant_global_average_pooling2d  (None, 1280)        3           ['quant_out_relu[0][0]']         \n",
      "  (QuantizeWrapperV2)                                                                             \n",
      "                                                                                                  \n",
      " quant_dense (QuantizeWrapperV2  (None, 1024)        1311749     ['quant_global_average_pooling2d[\n",
      " )                                                               0][0]']                          \n",
      "                                                                                                  \n",
      " quant_dense_1 (QuantizeWrapper  (None, 512)         524805      ['quant_dense[0][0]']            \n",
      " V2)                                                                                              \n",
      "                                                                                                  \n",
      " quant_dense_2 (QuantizeWrapper  (None, 256)         131333      ['quant_dense_1[0][0]']          \n",
      " V2)                                                                                              \n",
      "                                                                                                  \n",
      " quant_dense_3 (QuantizeWrapper  (None, 36)          9257        ['quant_dense_2[0][0]']          \n",
      " V2)                                                                                              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,255,285\n",
      "Trainable params: 4,166,884\n",
      "Non-trainable params: 88,401\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "save_dir = ''\n",
    "model = tf.keras.models.load_model(save_dir+'/modelMobileNetV2.h5')\n",
    "\n",
    "quantize_model = tfmot.quantization.keras.quantize_model\n",
    "\n",
    "# q_aware stands for for quantization aware.\n",
    "q_aware_model = quantize_model(model)\n",
    "\n",
    "# `quantize_model` requires a recompile.\n",
    "q_aware_model.compile(optimizer='adam',\n",
    "            #   loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "            loss=\"binary_crossentropy\",\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "q_aware_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "98/98 [==============================] - 451s 5s/step - loss: 0.2012 - accuracy: 0.0218 - val_loss: 0.2312 - val_accuracy: 0.0285\n",
      "Epoch 2/25\n",
      "98/98 [==============================] - 448s 5s/step - loss: 0.2709 - accuracy: 0.0218 - val_loss: 0.3138 - val_accuracy: 0.0285\n",
      "Epoch 3/25\n",
      "98/98 [==============================] - 448s 5s/step - loss: 0.3698 - accuracy: 0.0218 - val_loss: 0.4315 - val_accuracy: 0.0285\n",
      "Epoch 4/25\n",
      "98/98 [==============================] - 448s 5s/step - loss: 0.5047 - accuracy: 0.0218 - val_loss: 0.5844 - val_accuracy: 0.0285\n",
      "Epoch 5/25\n",
      "98/98 [==============================] - 446s 5s/step - loss: 0.7041 - accuracy: 0.0260 - val_loss: 0.8805 - val_accuracy: 0.0285\n",
      "Epoch 6/25\n",
      "98/98 [==============================] - 447s 5s/step - loss: 1.0492 - accuracy: 0.0295 - val_loss: 1.2336 - val_accuracy: 0.0285\n",
      "Epoch 6: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23d30d032c8>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
    "q_aware_model.fit(train_generator,\n",
    "                  batch_size=batch_size,\n",
    "                  epochs=25,\n",
    "                  validation_data=validation_generator,\n",
    "                  callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline test accuracy: 0.9749303460121155\n",
      "Quant test accuracy: 0.027855154126882553\n"
     ]
    }
   ],
   "source": [
    "_, baseline_model_accuracy = model.evaluate(test_generator, verbose=0)\n",
    "\n",
    "_, q_aware_model_accuracy = q_aware_model.evaluate(test_generator, verbose=0)\n",
    "\n",
    "print('Baseline test accuracy:', baseline_model_accuracy)\n",
    "print('Quant test accuracy:', q_aware_model_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Simple Model for Acc Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras.layers import Dropout\n",
    "\n",
    "# Define the simple model architecture.\n",
    "simple_model = keras.Sequential([\n",
    "  keras.layers.InputLayer(input_shape=input_shape),\n",
    "  # keras.layers.Reshape(target_shape=target_size),\n",
    "  keras.layers.Conv2D(filters=12, kernel_size=(3, 3), activation='relu'),\n",
    "  keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "  keras.layers.Flatten(),\n",
    "  keras.layers.Dense(36)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_model.compile(optimizer='adam',\n",
    "            #   loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "            loss = \"binary_crossentropy\",\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "98/98 [==============================] - 141s 1s/step - loss: 1.2323 - accuracy: 0.0222 - val_loss: 1.2295 - val_accuracy: 0.0285\n",
      "Epoch 2/25\n",
      "98/98 [==============================] - 139s 1s/step - loss: 1.2323 - accuracy: 0.0222 - val_loss: 1.2295 - val_accuracy: 0.0285\n",
      "Epoch 3/25\n",
      "98/98 [==============================] - 139s 1s/step - loss: 1.2323 - accuracy: 0.0222 - val_loss: 1.2295 - val_accuracy: 0.0285\n",
      "Epoch 4/25\n",
      "98/98 [==============================] - 137s 1s/step - loss: 1.2323 - accuracy: 0.0222 - val_loss: 1.2295 - val_accuracy: 0.0285\n",
      "Epoch 5/25\n",
      "98/98 [==============================] - 141s 1s/step - loss: 1.2323 - accuracy: 0.0222 - val_loss: 1.2295 - val_accuracy: 0.0285\n",
      "Epoch 6/25\n",
      "98/98 [==============================] - 134s 1s/step - loss: 1.2323 - accuracy: 0.0222 - val_loss: 1.2295 - val_accuracy: 0.0285\n",
      "Epoch 6: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23d2ea48f08>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_model.fit(\n",
    "  train_generator,\n",
    "  epochs=25,\n",
    "  validation_data=validation_generator,\n",
    "  callbacks=[es]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple model test accuracy: 0.027855154126882553\n"
     ]
    }
   ],
   "source": [
    "_, simple_model_accuracy = simple_model.evaluate(test_generator, verbose=0)\n",
    "print('Simple model test accuracy:', simple_model_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras.layers import Dropout\n",
    "\n",
    "model2=tf.keras.Sequential()\n",
    "\n",
    "model2.add(layers.Conv2D(filters = 32, kernel_size=(3, 3),  padding = \"same\", activation='relu', input_shape=input_shape))\n",
    "model2.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "# model2.add(Dropout(0.2))\n",
    "\n",
    "model2.add(layers.Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model2.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "# model2.add(Dropout(0.2))\n",
    "\n",
    "model2.add(layers.Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model2.add(layers.Flatten())\n",
    "\n",
    "model2.add(layers.Dense(128, activation='relu'))\n",
    "\n",
    "# model2.add(Dropout(0.5))\n",
    "model2.add(layers.Dense(36, activation='softmax'))\n",
    "\n",
    "model2.compile(optimizer= \"adam\",loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "history2 = model2.fit(\n",
    "  train_generator,\n",
    "  batch_size=batch_size,\n",
    "  epochs=25,\n",
    "  validation_data=validation_generator,\n",
    "  callbacks=[es]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_10 (Conv2D)          (None, 256, 256, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 128, 128, 32)     0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 126, 126, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 63, 63, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 61, 61, 128)       73856     \n",
      "                                                                 \n",
      " flatten_10 (Flatten)        (None, 476288)            0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 128)               60964992  \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 36)                4644      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 61,062,884\n",
      "Trainable params: 61,062,884\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras.layers import Dropout\n",
    "\n",
    "model2=tf.keras.Sequential()\n",
    "\n",
    "model2.add(layers.Conv2D(filters = 32, kernel_size=(3, 3),  padding = \"same\", activation='relu', input_shape=input_shape))\n",
    "model2.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "# model2.add(Dropout(0.2))\n",
    "\n",
    "model2.add(layers.Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model2.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "# model2.add(Dropout(0.2))\n",
    "\n",
    "model2.add(layers.Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model2.add(layers.Flatten())\n",
    "\n",
    "model2.add(layers.Dense(128, activation='relu'))\n",
    "\n",
    "# model2.add(Dropout(0.5))\n",
    "model2.add(layers.Dense(36, activation='softmax'))\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(optimizer= \"adam\",loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      " 4/98 [>.............................] - ETA: 3:37 - loss: 17.2786 - accuracy: 0.0312"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\PIL\\Image.py:980: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 272s 3s/step - loss: 4.0684 - accuracy: 0.0504 - val_loss: 3.2544 - val_accuracy: 0.1168\n",
      "Epoch 2/25\n",
      "98/98 [==============================] - 271s 3s/step - loss: 3.1036 - accuracy: 0.1406 - val_loss: 2.2569 - val_accuracy: 0.4672\n",
      "Epoch 3/25\n",
      "98/98 [==============================] - 280s 3s/step - loss: 2.2253 - accuracy: 0.3942 - val_loss: 1.2042 - val_accuracy: 0.8433\n",
      "Epoch 4/25\n",
      "98/98 [==============================] - 277s 3s/step - loss: 0.8924 - accuracy: 0.7849 - val_loss: 0.5025 - val_accuracy: 0.9402\n",
      "Epoch 5/25\n",
      "98/98 [==============================] - 263s 3s/step - loss: 0.3420 - accuracy: 0.9425 - val_loss: 0.5010 - val_accuracy: 0.9430\n",
      "Epoch 6/25\n",
      "98/98 [==============================] - 262s 3s/step - loss: 0.1422 - accuracy: 0.9762 - val_loss: 0.3388 - val_accuracy: 0.9573\n",
      "Epoch 7/25\n",
      "98/98 [==============================] - 263s 3s/step - loss: 0.0951 - accuracy: 0.9888 - val_loss: 0.2739 - val_accuracy: 0.9630\n",
      "Epoch 8/25\n",
      "98/98 [==============================] - 263s 3s/step - loss: 0.0572 - accuracy: 0.9910 - val_loss: 0.3359 - val_accuracy: 0.9516\n",
      "Epoch 9/25\n",
      "98/98 [==============================] - 263s 3s/step - loss: 0.0533 - accuracy: 0.9910 - val_loss: 0.2929 - val_accuracy: 0.9573\n",
      "Epoch 10/25\n",
      "98/98 [==============================] - 263s 3s/step - loss: 0.0565 - accuracy: 0.9917 - val_loss: 0.2526 - val_accuracy: 0.9601\n",
      "Epoch 11/25\n",
      "98/98 [==============================] - 264s 3s/step - loss: 0.0345 - accuracy: 0.9913 - val_loss: 0.2594 - val_accuracy: 0.9630\n",
      "Epoch 12/25\n",
      "98/98 [==============================] - 264s 3s/step - loss: 0.0446 - accuracy: 0.9913 - val_loss: 0.2616 - val_accuracy: 0.9516\n",
      "Epoch 13/25\n",
      "98/98 [==============================] - 264s 3s/step - loss: 0.0340 - accuracy: 0.9917 - val_loss: 0.2869 - val_accuracy: 0.9573\n",
      "Epoch 14/25\n",
      "98/98 [==============================] - 264s 3s/step - loss: 0.0445 - accuracy: 0.9913 - val_loss: 0.2347 - val_accuracy: 0.9544\n",
      "Epoch 15/25\n",
      "98/98 [==============================] - 263s 3s/step - loss: 0.0365 - accuracy: 0.9904 - val_loss: 0.2841 - val_accuracy: 0.9573\n",
      "Epoch 16/25\n",
      "98/98 [==============================] - 263s 3s/step - loss: 0.0307 - accuracy: 0.9904 - val_loss: 0.2692 - val_accuracy: 0.9573\n",
      "Epoch 17/25\n",
      "98/98 [==============================] - 263s 3s/step - loss: 0.0290 - accuracy: 0.9904 - val_loss: 0.3054 - val_accuracy: 0.9544\n",
      "Epoch 18/25\n",
      "98/98 [==============================] - 264s 3s/step - loss: 0.0314 - accuracy: 0.9907 - val_loss: 0.2636 - val_accuracy: 0.9544\n",
      "Epoch 19/25\n",
      "98/98 [==============================] - 263s 3s/step - loss: 0.0382 - accuracy: 0.9888 - val_loss: 0.3044 - val_accuracy: 0.9601\n",
      "Epoch 19: early stopping\n"
     ]
    }
   ],
   "source": [
    "history2 = model2.fit(\n",
    "  train_generator,\n",
    "  batch_size=batch_size,\n",
    "  epochs=25,\n",
    "  validation_data=validation_generator,\n",
    "  callbacks=[es]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Plot the train results\n",
    "acc = history2.history['accuracy']\n",
    "val_acc = history2.history['val_accuracy']\n",
    "loss = history2.history['loss']\n",
    "val_loss = history2.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, label='Training acc')\n",
    "plt.plot(epochs, val_acc, label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, label='Training loss')\n",
    "plt.plot(epochs, val_loss, label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 24s 2s/step - loss: 0.2977 - accuracy: 0.9610\n"
     ]
    }
   ],
   "source": [
    "result = model2.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " quantize_layer_3 (QuantizeL  (None, 256, 256, 3)      3         \n",
      " ayer)                                                           \n",
      "                                                                 \n",
      " quant_conv2d_10 (QuantizeWr  (None, 256, 256, 32)     963       \n",
      " apperV2)                                                        \n",
      "                                                                 \n",
      " quant_max_pooling2d_10 (Qua  (None, 128, 128, 32)     1         \n",
      " ntizeWrapperV2)                                                 \n",
      "                                                                 \n",
      " quant_conv2d_11 (QuantizeWr  (None, 126, 126, 64)     18627     \n",
      " apperV2)                                                        \n",
      "                                                                 \n",
      " quant_max_pooling2d_11 (Qua  (None, 63, 63, 64)       1         \n",
      " ntizeWrapperV2)                                                 \n",
      "                                                                 \n",
      " quant_conv2d_12 (QuantizeWr  (None, 61, 61, 128)      74115     \n",
      " apperV2)                                                        \n",
      "                                                                 \n",
      " quant_flatten_10 (QuantizeW  (None, 476288)           1         \n",
      " rapperV2)                                                       \n",
      "                                                                 \n",
      " quant_dense_10 (QuantizeWra  (None, 128)              60964997  \n",
      " pperV2)                                                         \n",
      "                                                                 \n",
      " quant_dense_11 (QuantizeWra  (None, 36)               4649      \n",
      " pperV2)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 61,063,357\n",
      "Trainable params: 61,062,884\n",
      "Non-trainable params: 473\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "quantize_model2 = tfmot.quantization.keras.quantize_model\n",
    "\n",
    "# q_aware stands for for quantization aware.\n",
    "q_aware_model2 = quantize_model2(model2)\n",
    "\n",
    "# `quantize_model` requires a recompile.\n",
    "q_aware_model2.compile(optimizer='adam',\n",
    "            #   loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "            loss=\"categorical_crossentropy\",\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "q_aware_model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\PIL\\Image.py:980: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 362s 4s/step - loss: 0.0978 - accuracy: 0.9795 - val_loss: 0.2349 - val_accuracy: 0.9573\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23d1b4a7988>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
    "q_aware_model2.fit(train_generator,\n",
    "                  batch_size=batch_size,\n",
    "                  epochs=1,\n",
    "                  validation_data=validation_generator,\n",
    "                  callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new model2 test accuracy: 0.961002767086029\n",
      "Quant test accuracy: 0.9582172632217407\n"
     ]
    }
   ],
   "source": [
    "_, baseline_model_accuracy2 = model2.evaluate(test_generator, verbose=0)\n",
    "\n",
    "_, q_aware_model_accuracy2 = q_aware_model2.evaluate(test_generator, verbose=0)\n",
    "\n",
    "print('new model2 test accuracy:', baseline_model_accuracy2)\n",
    "print('Quant test accuracy:', q_aware_model_accuracy2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = ''\n",
    "q_aware_model2.save(save_dir+'/q_model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, conv2d_10_layer_call_fn, conv2d_10_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, conv2d_11_layer_call_fn while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\YOUNGH~1\\AppData\\Local\\Temp\\tmpx9ftx56d\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\YOUNGH~1\\AppData\\Local\\Temp\\tmpx9ftx56d\\assets\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py:765: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(q_aware_model2)\n",
    "# converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "quantized_tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model.\n",
    "with open('q_model2.tflite', 'wb') as f:\n",
    "  f.write(quantized_tflite_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
